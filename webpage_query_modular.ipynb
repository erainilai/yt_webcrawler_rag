{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423a73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (4.14.3)\n",
      "Requirement already satisfied: tldextract in ./.venv/lib/python3.12/site-packages (5.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2026.2.25)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in ./.venv/lib/python3.12/site-packages (from tldextract) (3.0.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in ./.venv/lib/python3.12/site-packages (from tldextract) (3.24.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (1.2.10)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.12/site-packages (1.13.2)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.57.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in ./.venv/lib/python3.12/site-packages (from langchain) (1.2.15)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from langchain) (1.0.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.12/site-packages (from faiss-cpu) (2.4.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from faiss-cpu) (26.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.36.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2026.2.19)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.7.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (9.1.4)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2026.2.25)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.11.5 in ./.venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 tldextract\n",
    "!pip install langchain faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b36f4",
   "metadata": {},
   "source": [
    "*****************  Import Libraries  **********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c3099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tldextract\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import html2text\n",
    "import requests\n",
    "\n",
    "#from langchain.vectorstores import FAISS\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.llms import HuggingFacePipeline\n",
    "#from langchain.chains import RetrievalQA\n",
    "#from langchain.prompts import PromptTemplate\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "#from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "\n",
    "# the import succeeds once the updated package is loaded\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# or other text splitters you are using\n",
    "\n",
    "\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "#from langchain.chains import RetrievalQA\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import re\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c53a8",
   "metadata": {},
   "source": [
    "********************************  URL Input ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f96919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL loaded: https://python.langchain.com/docs/introduction/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://python.langchain.com/docs/introduction/'\n",
    "print(\"URL loaded:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff402727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://python.langchain.com/docs/introduction/\n",
      "Scraping: https://python.langchain.com/docs/introduction/#content-area\n",
      "Scraping: https://python.langchain.com/\n",
      "Scraping: https://chat.langchain.com/\n",
      "Scraping: https://smith.langchain.com/\n",
      "Scraping: https://python.langchain.com/oss/python/deepagents/overview\n",
      "Scraping: https://python.langchain.com/oss/python/langchain/overview\n",
      "Scraping: https://python.langchain.com/oss/python/langgraph/overview\n",
      "Scraping: https://python.langchain.com/oss/python/integrations/providers/overview\n",
      "Scraping: https://python.langchain.com/oss/python/learn\n",
      "\n",
      "Successfully saved scraped data to scraped_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_website(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"Scraping: {current_url}\")\n",
    "\n",
    "            # Extract visible text\n",
    "            # page_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "            # extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Instead of just 'p', target a wider set of content tags\n",
    "            content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "            all_content = []\n",
    "            for tag_name in content_tags:\n",
    "                all_content.extend(soup.find_all(tag_name))\n",
    "                \n",
    "            page_text = ' '.join([tag.get_text() for tag in all_content])\n",
    "            extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Extract internal links\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "                if base_domain in parsed.netloc and full_url not in visited:\n",
    "                    to_visit.append(full_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website(url)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(scraped_text)\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61191a",
   "metadata": {},
   "source": [
    "********************************  Scrap & clean the text  ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607b5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/docs/introduction/\n",
      "âœ… Added to queue https://python.langchain.com/docs/introduction/#content-area 2\n",
      "âŒ Skipped https://python.langchain.com/ 2\n",
      "âœ… Added to queue https://chat.langchain.com/ 3\n",
      "âœ… Added to queue https://smith.langchain.com/ 4\n",
      "âŒ Skipped https://smith.langchain.com/ 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/deepagents/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langgraph/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/integrations/providers/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/learn 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/reference/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/contributing/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/install 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/quickstart 4\n",
      "âŒ Skipped https://docs.langchain.com/oss/python/releases/changelog 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/philosophy 4\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/langchain/agents 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/models 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/messages 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/tools 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/short-term-memory 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/structured-output 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/overview 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/built-in 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/custom 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/guardrails 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/runtime 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/context-engineering 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/mcp 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/human-in-the-loop 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/retrieval 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/long-term-memory 5\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/langchain/studio 6\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/test 6\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/langchain/ui 7\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/deploy 7\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/observability 7\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#create-an-agent 7\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#core-benefits 7\n",
      "âŒ Skipped https://python.langchain.com/oss/python/integrations/providers/overview 7\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/deepagents/overview 8\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 8\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/langgraph/overview 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 9\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#create-an-agent 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/install 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/quickstart 9\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#core-benefits 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/models 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 9\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langgraph/overview 9\n",
      "âœ… Added to queue https://python.langchain.com/langsmith/home 10\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/docs/introduction/#content-area\n",
      "\n",
      "ðŸ”Ž Scraping new: https://chat.langchain.com/\n",
      "\n",
      "ðŸ”Ž Scraping new: https://smith.langchain.com/\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/langchain/agents\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/langchain/studio\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/langchain/ui\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/deepagents/overview\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/langgraph/overview\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/langsmith/home\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "def scrape_website_focused_markdown(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_markdown = \"\" \n",
    "    total_url_collection = 1\n",
    "    # Initialize the converter\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = False\n",
    "    h.body_width = 0 \n",
    "\n",
    "    # Define the tags we want to keep\n",
    "    content_tags = ['p', 'h1', 'h2', 'h3', 'code']\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"\\nðŸ”Ž Scraping new: {current_url}\")\n",
    "\n",
    "            # --- Focused HTML Extraction ---\n",
    "            isolated_html = \"\"\n",
    "\n",
    "            # Collect only desired tags, ignoring menu/sidebar\n",
    "            all_content_tags = soup.find_all(content_tags)\n",
    "            for tag in all_content_tags:\n",
    "                if tag.find_parent(class_=lambda c: c and any(x in c.lower() for x in [\"menu\", \"sidebar\"])):\n",
    "                    continue\n",
    "                isolated_html += tag.prettify()\n",
    "\n",
    "            # Convert extracted HTML to Markdown\n",
    "            if isolated_html.strip():\n",
    "                markdown_text = h.handle(isolated_html)\n",
    "                extracted_markdown += f\"\\n\\n--- Page: {current_url} ---\\n\\n\"\n",
    "                extracted_markdown += markdown_text\n",
    "            \n",
    "            # --- Link Extraction with user confirmation ---\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "\n",
    "                if total_url_collection < max_pages:\n",
    "                    if base_domain in parsed.netloc and full_url not in visited:\n",
    "                        choice = input(f\"ðŸ‘‰ Found link: {full_url}\\nDo you want to crawl this link? (y/n): \").strip().lower()\n",
    "                        if choice == \"y\":\n",
    "                            to_visit.append(full_url)\n",
    "                            total_url_collection = total_url_collection + 1\n",
    "                            print(\"âœ… Added to queue\", full_url, total_url_collection)\n",
    "                        else:\n",
    "                            print(\"âŒ Skipped\", full_url, total_url_collection)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_markdown    \n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website_focused_markdown(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e81fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved scraped data to scraped_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_scraped_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean scraped text:\n",
    "    - Collapse multiple spaces into one (but keep newlines)\n",
    "    - Collapse multiple blank lines into a single newline\n",
    "    - Strip leading/trailing spaces\n",
    "    \"\"\"\n",
    "    # Replace multiple spaces (but not newlines) with one\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    # Collapse multiple blank lines into a single newline\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
    "\n",
    "    # Strip spaces at line starts/ends\n",
    "    text = re.sub(r'[ \\t]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ \\t]+', '\\n', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "clean_text   = clean_scraped_text(scraped_text)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(clean_text)\n",
    "\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72777fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 6 chunks.\n"
     ]
    }
   ],
   "source": [
    "scraped_text = ''\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'r', encoding='utf-8') as f:\n",
    "    scraped_text = f.read()\n",
    "\n",
    "def chunk_text(text, chunk_size=1500, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Chunk the scraped text\n",
    "chunks = chunk_text(scraped_text)\n",
    "print(f\"Text split into {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8223e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--- Page: https://python.langchain.com/docs/introduction/ ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/docs/introduction/#content-area ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent',\n",
       " '##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://chat.langchain.com/ ---\\n\\nLoading...\\n\\n--- Page: https://python.langchain.com/oss/python/langchain/agents ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent',\n",
       " '##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/langchain/studio ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface',\n",
       " '##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/langchain/ui ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/deepagents/overview ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent',\n",
       " '##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/langgraph/overview ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits',\n",
       " '##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/langsmith/home ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467df895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Cell 6: Load Embedding Model\n",
    "# Load embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a275d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create FAISS vector store\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVector store created.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/learn/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/learn/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:155\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/learn/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:130\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    137\u001b[39m     msg = (\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/learn/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/learn/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1152\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m             all_embeddings = np.asarray([emb.float().numpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[32m   1151\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m             all_embeddings = np.asarray([\u001b[43memb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[32m   1153\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np.ndarray):\n\u001b[32m   1154\u001b[39m     all_embeddings = [torch.from_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_texts(chunks, embedding_model)\n",
    "print(\"Vector store created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d117f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Use the following extracted content to answer the question.\n",
    "Answer in a clear, factual, and concise way. If the answer is not in the context, say \"I donâ€™t know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "map_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Prompt for the reduce step (combine answers)\n",
    "combine_prompt = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "The following are answers from different documents:\n",
    "{summaries}\n",
    "\n",
    "Given the above, provide a final, concise answer to the question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question. Use the document to answer.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Refine prompt (subsequent documents)\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "We have an existing answer: {existing_answer}\n",
    "\n",
    "Here is another document that may help refine it:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Update the answer if the document provides new useful information. \n",
    "If not, keep the original answer.\n",
    "\n",
    "Refined Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "rerank_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide:\n",
    "1. An answer to the question (if the document is relevant).\n",
    "2. A relevance score between 0 and 10 (higher means more relevant).\n",
    "\n",
    "Format:\n",
    "Answer: <your answer here>\n",
    "Score: <number between 0 and 10>\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56f774",
   "metadata": {},
   "source": [
    "# =====================================================================\n",
    "# ðŸ”¹ chain_type in RetrievalQA\n",
    "# =====================================================================\n",
    "#\n",
    "# \"stuff\"\n",
    "#   - Simplest method.\n",
    "#   - All retrieved documents are stuffed (concatenated) into the prompt \n",
    "#     along with your query.\n",
    "#   - Works well if documents are short and the number of tokens is small.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_reduce\"\n",
    "#   - Each retrieved document is first processed individually with the LLM (map step).\n",
    "#   - Then the outputs are combined/summarized (reduce step).\n",
    "#   - Better for handling many long documents, since it avoids hitting token limits.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"refine\"\n",
    "#   - Processes documents sequentially.\n",
    "#   - Starts with the first document â†’ generates an initial answer.\n",
    "#   - Then refines that answer using each subsequent document.\n",
    "#   - Useful when you want the model to incrementally improve its response.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_rerank\"\n",
    "#   - LLM scores each document separately for relevance and produces an answer.\n",
    "#   - The best-scored answer is returned.\n",
    "#   - Useful when documents may not all be relevant.\n",
    "#\n",
    "# =====================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee623e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA chain ready.\n"
     ]
    }
   ],
   "source": [
    "def load_qa_chain(vectorstore, model_name=\"google/flan-t5-base\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizeder=tokenizer)\n",
    "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "                                            llm=llm,\n",
    "                                            retriever=retriever,\n",
    "                                            chain_type=\"stuff\",  # This tells LangChain to use simple context stuffing\n",
    "                                            chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                            return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "def load_groq_qa_chain(vectorstore, model_name, chain_type):\n",
    "    llm       = ChatGroq(model=model_name, temperature=0)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    if chain_type == \"stuff\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"stuff\",\n",
    "                                                chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                                )\n",
    "    elif chain_type == \"map_reduce\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_reduce\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                                        \"question_prompt\": map_prompt,   # ðŸ‘ˆ must be question_prompt\n",
    "                                                                        \"combine_prompt\": combine_prompt\n",
    "                                                                    },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "\n",
    "    elif chain_type == \"refine\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"refine\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                    \"question_prompt\": question_prompt,\n",
    "                                                    \"refine_prompt\": refine_prompt,\n",
    "                                                    \"document_variable_name\": \"context\"  # ðŸ‘ˆ matches your prompt template\n",
    "                                                },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    \n",
    "    elif chain_type == \"map_rerank\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_rerank\",\n",
    "                                                chain_type_kwargs={\"prompt\": rerank_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "# Load QA chain\n",
    "# qa_chain = load_qa_chain(vectorstore, 'google/flan-t5-base')\n",
    "\n",
    "print(\"QA chain ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ebcfd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lanchain vs langsmith vs agents\n"
     ]
    }
   ],
   "source": [
    "query  = input(\"Ask a question about the website: \")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85cef740",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m qa_groq_chain = load_groq_qa_chain(\u001b[43mvectorstore\u001b[49m, model_name=\u001b[33m\"\u001b[39m\u001b[33mllama-3.1-8b-instant\u001b[39m\u001b[33m\"\u001b[39m, chain_type=\u001b[33m\"\u001b[39m\u001b[33mstuff\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m result = qa_groq_chain({\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: query})\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m docs \u001b[38;5;129;01min\u001b[39;00m result[\u001b[33m'\u001b[39m\u001b[33msource_documents\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[31mNameError\u001b[39m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"stuff\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad2e1d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d95bc5377c944f2886e1c74f2b8fc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\POOJA\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd2fcf133be43f8953864ee501d252b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ef36425c0b4f4fa205f88bcb592db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19991e791ddd4923b9e99f7813b17287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c46da4719a4077a1dc9871e9ed6231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain youâ€™ll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) youâ€™ll find short answers to â€œHow do Iâ€¦.?â€ types of questions. These how-to guides donâ€™t cover topics in depth â€“ youâ€™ll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits Â¶\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraphâ€™s ecosystem Â¶\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources Â¶\\n\\n## Acknowledgements Â¶\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Here's a final, concise comparison of LangChain and LangGraph in bullet points:\n",
      "\n",
      "**Similarities:**\n",
      "\n",
      "* Both are part of the LangChain ecosystem\n",
      "* Both are designed to work with Large Language Models (LLMs)\n",
      "* Both aim to make it easier to build and deploy AI applications\n",
      "* Both integrate with hundreds of providers, including large language models and related technologies\n",
      "\n",
      "**Differences:**\n",
      "\n",
      "* **Purpose:**\n",
      "\t+ Langchain: A general-purpose framework for building AI applications, providing a set of tools and libraries for working with LLMs.\n",
      "\t+ LangGraph: A specific tool for building stateful, multi-actor applications with LLMs, designed for production-grade agents.\n",
      "* **Integration:**\n",
      "\t+ Langchain: Can be used on its own or integrated with other tools and libraries.\n",
      "\t+ LangGraph: Integrates smoothly with LangChain, but can also be used independently.\n",
      "* **Scalability:**\n",
      "\t+ Langchain: Can handle a variety of workloads, from small to large-scale applications.\n",
      "\t+ LangGraph: Optimized for high-performance, scalable applications that require multiple actors and LLMs.\n",
      "* **Abstraction:**\n",
      "\t+ Langchain: Abstracts prompts and architecture.\n",
      "\t+ LangGraph: Does not abstract these aspects.\n",
      "* **Functionality:**\n",
      "\t+ Langchain: Provides a full suite of tools for building agents.\n",
      "\t+ LangGraph: Focuses on providing a supporting infrastructure.\n",
      "* **Language:**\n",
      "\t+ Langchain: Available in multiple languages, including Python.\n",
      "\t+ LangGraph: Has a separate JavaScript version (LangGraphJS).\n",
      "* **Security:**\n",
      "\t+ Langchain: Has a dedicated security page with best practices for developing safely with the framework.\n",
      "\t+ LangGraph: Security features are not explicitly mentioned in the provided context.\n",
      "* **Community:**\n",
      "\t+ Langchain: Has a more extensive community and ecosystem, with a developer's guide and guidelines for contributing.\n",
      "\t+ LangGraph: Community and contribution guidelines are not explicitly mentioned in the provided context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"map_reduce\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c74f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain youâ€™ll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) youâ€™ll find short answers to â€œHow do Iâ€¦.?â€ types of questions. These how-to guides donâ€™t cover topics in depth â€“ youâ€™ll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits Â¶\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraphâ€™s ecosystem Â¶\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources Â¶\\n\\n## Acknowledgements Â¶\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Based on the provided documents, here's a comparison of Langchain and LangGraph in bullet points:\n",
      "\n",
      "**Langchain vs LangGraph:**\n",
      "\n",
      "* **Purpose:**\n",
      "  * Langchain: A framework for developing applications powered by large language models (LLMs), simplifying every stage of the LLM application lifecycle.\n",
      "  * LangGraph: A specific part of the Langchain ecosystem, providing a deeper dive into LangGraph concepts, and can be used independently of LangChain. It's used for building stateful, multi-actor applications with LLMs.\n",
      "* **Documentation:**\n",
      "  * Langchain: Has a growing list of integrations, an API reference section for full documentation, a troubleshooting guide for resolving common errors, and tutorials, how-to guides, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own conceptual guide, a separate page for deeper dive into LangGraph concepts, a link to the LangChain Academy course on Introduction to LangGraph, and tutorials, how-to guides.\n",
      "* **Integration:**\n",
      "  * Langchain: Integrates with various tools and components, including chat models, vector stores, and other LangChain components.\n",
      "  * LangGraph: Integrates smoothly with LangChain, but can be used without it, and is used by production-grade agents trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* **Level of Explanation:**\n",
      "  * Langchain: Provides high-level explanations of all LangChain concepts.\n",
      "  * LangGraph: Offers a deeper dive into LangGraph concepts, suggesting a more detailed explanation.\n",
      "* **Learning Resources:**\n",
      "  * Langchain: Offers tutorials, how-to guides, an API reference, a troubleshooting guide, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Tutorials and Guides:**\n",
      "  * Langchain: Has a tutorials section with a list of tutorials, including a link to LangGraph tutorials, and a troubleshooting guide.\n",
      "  * LangGraph: Has its own tutorials section and how-to guides, with a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Core Benefits:**\n",
      "  * LangGraph: Provides low-level supporting infrastructure for any long-running, stateful workflow or agent, and does not abstract prompts or architecture.\n",
      "* **Ecosystem:**\n",
      "  * LangGraph: Integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents.\n",
      "* **Additional Resources:**\n",
      "  * LangGraph: The JS version of LangGraph is available on the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/).\n",
      "  * Langchain: Provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* **Inspiration:**\n",
      "  * LangGraph: Inspired by Pregel, Apache Beam, and NetworkX.\n",
      "\n",
      "**New Information:**\n",
      "\n",
      "* Langchain simplifies every stage of the LLM application lifecycle.\n",
      "* Langchain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers.\n",
      "* LangGraph is used for building stateful, multi-actor applications with LLMs.\n",
      "* LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* Langchain provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* LangGraph has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"refine\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
