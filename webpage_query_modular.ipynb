{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /Users/sathiya.c/git/ai/yt_webcrawler_rag/.venv/bin/pip: bad interpreter: /Users/sathiya.c/git/learn/yt_webcrawler_rag/.venv/bin/python: no such file or directory\n",
      "zsh:1: /Users/sathiya.c/git/ai/yt_webcrawler_rag/.venv/bin/pip: bad interpreter: /Users/sathiya.c/git/learn/yt_webcrawler_rag/.venv/bin/python: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 tldextract\n",
    "!pip install langchain faiss-cpu transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b36f4",
   "metadata": {},
   "source": [
    "*****************  Import Libraries  **********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5c3099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = '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'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tldextract\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import html2text\n",
    "import requests\n",
    "\n",
    "#from langchain.vectorstores import FAISS\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.llms import HuggingFacePipeline\n",
    "#from langchain.chains import RetrievalQA\n",
    "#from langchain.prompts import PromptTemplate\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "#from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "\n",
    "# the import succeeds once the updated package is loaded\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# or other text splitters you are using\n",
    "\n",
    "\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "#from langchain.chains import RetrievalQA\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import re\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c53a8",
   "metadata": {},
   "source": [
    "********************************  URL Input ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f96919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL loaded: https://python.langchain.com/docs/introduction/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://python.langchain.com/docs/introduction/'\n",
    "print(\"URL loaded:\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff402727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://python.langchain.com/docs/introduction/\n",
      "Scraping: https://python.langchain.com/docs/introduction/#content-area\n",
      "Scraping: https://python.langchain.com/\n",
      "Scraping: https://chat.langchain.com/\n",
      "Scraping: https://smith.langchain.com/\n",
      "Scraping: https://python.langchain.com/oss/python/deepagents/overview\n",
      "Scraping: https://python.langchain.com/oss/python/langchain/overview\n",
      "Scraping: https://python.langchain.com/oss/python/langgraph/overview\n",
      "Scraping: https://python.langchain.com/oss/python/integrations/providers/overview\n",
      "Scraping: https://python.langchain.com/oss/python/learn\n",
      "\n",
      "Successfully saved scraped data to scraped_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_website(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"Scraping: {current_url}\")\n",
    "\n",
    "            # Extract visible text\n",
    "            # page_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "            # extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Instead of just 'p', target a wider set of content tags\n",
    "            content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "            all_content = []\n",
    "            for tag_name in content_tags:\n",
    "                all_content.extend(soup.find_all(tag_name))\n",
    "                \n",
    "            page_text = ' '.join([tag.get_text() for tag in all_content])\n",
    "            extracted_text += page_text + \"\\n\"\n",
    "\n",
    "            # Extract internal links\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "                if base_domain in parsed.netloc and full_url not in visited:\n",
    "                    to_visit.append(full_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website(url)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(scraped_text)\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61191a",
   "metadata": {},
   "source": [
    "********************************  Scrap & clean the text  ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607b5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/docs/introduction/\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#content-area 1\n",
      "âœ… Added to queue https://python.langchain.com/ 2\n",
      "âŒ Skipped https://chat.langchain.com/ 2\n",
      "âœ… Added to queue https://smith.langchain.com/ 3\n",
      "âŒ Skipped https://smith.langchain.com/ 3\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/deepagents/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langgraph/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/integrations/providers/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/learn 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/reference/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/contributing/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/install 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/quickstart 4\n",
      "âŒ Skipped https://docs.langchain.com/oss/python/releases/changelog 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/philosophy 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/models 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/messages 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/tools 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/short-term-memory 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/structured-output 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/overview 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/built-in 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/middleware/custom 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/guardrails 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/runtime 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/context-engineering 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/mcp 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/human-in-the-loop 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/retrieval 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/long-term-memory 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/studio 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/test 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/ui 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/deploy 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/observability 4\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#create-an-agent 4\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#core-benefits 4\n",
      "âŒ Skipped https://python.langchain.com/oss/python/integrations/providers/overview 4\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/deepagents/overview 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langgraph/overview 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 5\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#create-an-agent 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/install 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/quickstart 5\n",
      "âŒ Skipped https://python.langchain.com/docs/introduction/#core-benefits 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/models 5\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/agents 5\n",
      "âœ… Added to queue https://python.langchain.com/oss/python/langgraph/overview 6\n",
      "âœ… Added to queue https://python.langchain.com/langsmith/home 7\n",
      "âŒ Skipped https://python.langchain.com/use-these-docs 7\n",
      "âŒ Skipped https://python.langchain.com/oss/python/langchain/install 7\n",
      "âœ… Added to queue https://python.langchain.com/ 8\n",
      "âŒ Skipped https://forum.langchain.com/ 8\n",
      "âŒ Skipped https://changelog.langchain.com/ 8\n",
      "âŒ Skipped https://academy.langchain.com/ 8\n",
      "âŒ Skipped https://trust.langchain.com/ 8\n",
      "âŒ Skipped https://langchain.com/ 8\n",
      "âŒ Skipped https://langchain.com/about 8\n",
      "âŒ Skipped https://langchain.com/careers 8\n",
      "âŒ Skipped https://blog.langchain.com/ 8\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/\n",
      "âŒ Skipped https://python.langchain.com/#content-area 8\n",
      "âŒ Skipped https://chat.langchain.com/ 8\n",
      "âœ… Added to queue https://smith.langchain.com/ 9\n",
      "âœ… Added to queue https://smith.langchain.com/ 10\n",
      "\n",
      "ðŸ”Ž Scraping new: https://smith.langchain.com/\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/deepagents/overview\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/oss/python/langgraph/overview\n",
      "\n",
      "ðŸ”Ž Scraping new: https://python.langchain.com/langsmith/home\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# content_tags = ['p', 'h1', 'h2', 'h3', 'li', 'code', 'pre']\n",
    "def scrape_website_focused_markdown(url, max_pages=10):\n",
    "    visited = set()\n",
    "    to_visit = [url]\n",
    "    extracted_markdown = \"\" \n",
    "    total_url_collection = 1\n",
    "    # Initialize the converter\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = False\n",
    "    h.body_width = 0 \n",
    "\n",
    "    # Define the tags we want to keep\n",
    "    content_tags = ['p', 'h1', 'h2', 'h3', 'code']\n",
    "\n",
    "    while to_visit and len(visited) < max_pages:\n",
    "        current_url = to_visit.pop(0)\n",
    "        if current_url in visited:\n",
    "            continue\n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            visited.add(current_url)\n",
    "            print(f\"\\nðŸ”Ž Scraping new: {current_url}\")\n",
    "\n",
    "            # --- Focused HTML Extraction ---\n",
    "            isolated_html = \"\"\n",
    "\n",
    "            # Collect only desired tags, ignoring menu/sidebar\n",
    "            all_content_tags = soup.find_all(content_tags)\n",
    "            for tag in all_content_tags:\n",
    "                if tag.find_parent(class_=lambda c: c and any(x in c.lower() for x in [\"menu\", \"sidebar\"])):\n",
    "                    continue\n",
    "                isolated_html += tag.prettify()\n",
    "\n",
    "            # Convert extracted HTML to Markdown\n",
    "            if isolated_html.strip():\n",
    "                markdown_text = h.handle(isolated_html)\n",
    "                extracted_markdown += f\"\\n\\n--- Page: {current_url} ---\\n\\n\"\n",
    "                extracted_markdown += markdown_text\n",
    "            \n",
    "            # --- Link Extraction with user confirmation ---\n",
    "            for link_tag in soup.find_all('a', href=True):\n",
    "                href = link_tag['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                parsed = urlparse(full_url)\n",
    "                base_domain = tldextract.extract(url).domain\n",
    "\n",
    "                if total_url_collection < max_pages:\n",
    "                    if base_domain in parsed.netloc and full_url not in visited:\n",
    "                        choice = input(f\"ðŸ‘‰ Found link: {full_url}\\nDo you want to crawl this link? (y/n): \").strip().lower()\n",
    "                        if choice == \"y\":\n",
    "                            to_visit.append(full_url)\n",
    "                            total_url_collection = total_url_collection + 1\n",
    "                            print(\"âœ… Added to queue\", full_url, total_url_collection)\n",
    "                        else:\n",
    "                            print(\"âŒ Skipped\", full_url, total_url_collection)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to scrape {current_url}: {e}\")\n",
    "    \n",
    "    return extracted_markdown    \n",
    "\n",
    "# Execute scraping\n",
    "scraped_text = scrape_website_focused_markdown(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e81fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved scraped data to scraped_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_scraped_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean scraped text:\n",
    "    - Collapse multiple spaces into one (but keep newlines)\n",
    "    - Collapse multiple blank lines into a single newline\n",
    "    - Strip leading/trailing spaces\n",
    "    \"\"\"\n",
    "    # Replace multiple spaces (but not newlines) with one\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    # Collapse multiple blank lines into a single newline\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)\n",
    "\n",
    "    # Strip spaces at line starts/ends\n",
    "    text = re.sub(r'[ \\t]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ \\t]+', '\\n', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "clean_text   = clean_scraped_text(scraped_text)\n",
    "\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'w', encoding='utf-8') as f:\n",
    "    f.write(clean_text)\n",
    "\n",
    "print(f\"\\nSuccessfully saved scraped data to {scrapped_file_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72777fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 4 chunks.\n"
     ]
    }
   ],
   "source": [
    "scraped_text = ''\n",
    "scrapped_file_data = \"scraped_data.txt\"\n",
    "with open(scrapped_file_data, 'r', encoding='utf-8') as f:\n",
    "    scraped_text = f.read()\n",
    "\n",
    "def chunk_text(text, chunk_size=1500, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Chunk the scraped text\n",
    "chunks = chunk_text(scraped_text)\n",
    "print(f\"Text split into {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8223e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--- Page: https://python.langchain.com/docs/introduction/ ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/ ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent',\n",
       " '##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/deepagents/overview ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\\n\\n##\\n\\n\\u200b',\n",
       " '##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/oss/python/langgraph/overview ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany\\n\\n--- Page: https://python.langchain.com/langsmith/home ---\\n\\nPython\\n\\n# LangChain overview\\n\\nLangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\\n\\n##\\n\\n\\u200b\\n\\nCreate an agent',\n",
       " '##\\n\\n\\u200b\\n\\nCreate an agent\\n\\n` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It\\'s always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\\n\\n##\\n\\n\\u200b\\n\\nCore benefits\\n\\n## Standard model interface\\n\\n## Easy to use, highly flexible agent\\n\\n## Built on top of LangGraph\\n\\n## Debug with LangSmith\\n\\nWas this page helpful?\\n\\nResources\\n\\nCompany']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467df895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/w1byhqp57m3bnrnzy9k8y5yw0000gp/T/ipykernel_75257/1864675297.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§  Cell 6: Load Embedding Model\n",
    "# Load embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Embedding model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a275d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created.\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_texts(chunks, embedding_model)\n",
    "print(\"Vector store created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d117f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Use the following extracted content to answer the question.\n",
    "Answer in a clear, factual, and concise way. If the answer is not in the context, say \"I donâ€™t know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "map_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Prompt for the reduce step (combine answers)\n",
    "combine_prompt = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"],\n",
    "    template=\"\"\"\n",
    "The following are answers from different documents:\n",
    "{summaries}\n",
    "\n",
    "Given the above, provide a final, concise answer to the question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question. Use the document to answer.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Refine prompt (subsequent documents)\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "We have an existing answer: {existing_answer}\n",
    "\n",
    "Here is another document that may help refine it:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Update the answer if the document provides new useful information. \n",
    "If not, keep the original answer.\n",
    "\n",
    "Refined Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "rerank_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are given a document and a question.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide:\n",
    "1. An answer to the question (if the document is relevant).\n",
    "2. A relevance score between 0 and 10 (higher means more relevant).\n",
    "\n",
    "Format:\n",
    "Answer: <your answer here>\n",
    "Score: <number between 0 and 10>\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56f774",
   "metadata": {},
   "source": [
    "# =====================================================================\n",
    "# ðŸ”¹ chain_type in RetrievalQA\n",
    "# =====================================================================\n",
    "#\n",
    "# \"stuff\"\n",
    "#   - Simplest method.\n",
    "#   - All retrieved documents are stuffed (concatenated) into the prompt \n",
    "#     along with your query.\n",
    "#   - Works well if documents are short and the number of tokens is small.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_reduce\"\n",
    "#   - Each retrieved document is first processed individually with the LLM (map step).\n",
    "#   - Then the outputs are combined/summarized (reduce step).\n",
    "#   - Better for handling many long documents, since it avoids hitting token limits.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"refine\"\n",
    "#   - Processes documents sequentially.\n",
    "#   - Starts with the first document â†’ generates an initial answer.\n",
    "#   - Then refines that answer using each subsequent document.\n",
    "#   - Useful when you want the model to incrementally improve its response.\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# \"map_rerank\"\n",
    "#   - LLM scores each document separately for relevance and produces an answer.\n",
    "#   - The best-scored answer is returned.\n",
    "#   - Useful when documents may not all be relevant.\n",
    "#\n",
    "# =====================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee623e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA chain ready.\n"
     ]
    }
   ],
   "source": [
    "def load_qa_chain(vectorstore, model_name=\"google/flan-t5-base\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizeder=tokenizer)\n",
    "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "                                            llm=llm,\n",
    "                                            retriever=retriever,\n",
    "                                            chain_type=\"stuff\",  # This tells LangChain to use simple context stuffing\n",
    "                                            chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                            return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "def load_groq_qa_chain(vectorstore, model_name, chain_type):\n",
    "    llm       = ChatGroq(model=model_name, temperature=0)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    if chain_type == \"stuff\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"stuff\",\n",
    "                                                chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                                )\n",
    "    elif chain_type == \"map_reduce\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_reduce\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                                        \"question_prompt\": map_prompt,   # ðŸ‘ˆ must be question_prompt\n",
    "                                                                        \"combine_prompt\": combine_prompt\n",
    "                                                                    },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "\n",
    "    elif chain_type == \"refine\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"refine\",\n",
    "                                                chain_type_kwargs={\n",
    "                                                    \"question_prompt\": question_prompt,\n",
    "                                                    \"refine_prompt\": refine_prompt,\n",
    "                                                    \"document_variable_name\": \"context\"  # ðŸ‘ˆ matches your prompt template\n",
    "                                                },\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    \n",
    "    elif chain_type == \"map_rerank\":\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "                                                llm=llm,\n",
    "                                                retriever=retriever,\n",
    "                                                chain_type=\"map_rerank\",\n",
    "                                                chain_type_kwargs={\"prompt\": rerank_prompt},\n",
    "                                                return_source_documents=True\n",
    "                                            )\n",
    "    return qa_chain\n",
    "\n",
    "# Load QA chain\n",
    "# qa_chain = load_qa_chain(vectorstore, 'google/flan-t5-base')\n",
    "\n",
    "print(\"QA chain ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebcfd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare lang chain, langgraph, lang smith\n"
     ]
    }
   ],
   "source": [
    "query  = input(\"Ask a question about the website: \")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85cef740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/w1byhqp57m3bnrnzy9k8y5yw0000gp/T/ipykernel_75257/816384525.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
      "  result = qa_groq_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/oss/python/langgraph/overview ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/langsmith/home ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent'\n",
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company'\n",
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/oss/python/deepagents/overview ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹'\n",
      "page_content='--- Page: https://python.langchain.com/docs/introduction/ ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/ ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent'\n",
      "Answer: Based on the provided context, here's a comparison of LangChain, LangGraph, and LangSmith:\n",
      "\n",
      "1. **LangChain**: An open-source framework with a pre-built agent architecture and integrations for any model or tool. It allows users to build agents that adapt quickly to the evolving ecosystem. LangChain provides a standard model interface, is easy to use, and highly flexible.\n",
      "\n",
      "2. **LangGraph**: LangChain is built on top of LangGraph. LangGraph is not explicitly described in the provided context, but it's likely a foundational component of LangChain, providing the underlying structure and functionality.\n",
      "\n",
      "3. **LangSmith**: LangSmith is a tool used for debugging LangChain agents. It's mentioned as a core benefit of LangChain, allowing users to debug their agents more efficiently.\n",
      "\n",
      "In summary, LangChain is the framework, LangGraph is a foundational component, and LangSmith is a debugging tool used in conjunction with LangChain.\n"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"stuff\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad2e1d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sathiya.c/git/ai/yt_webcrawler_rag/.venv/lib/python3.12/site-packages/langchain_core/language_models/base.py:336: UserWarning: Using fallback GPT-2 tokenizer for token counting. Token counts may be inaccurate for non-GPT-2 models. For accurate counts, use a model-specific method if available.\n",
      "  return len(self.get_token_ids(text))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee2eefef2845508f107af683ee5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb78eeeadad24f2db3a95a7c1bf3a93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377333a6b5f14c4e9be209412cdc2619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aed22e70334c8caef9611ecfc278fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dab2c3928f4ee3b7ab26574e99ce1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/oss/python/langgraph/overview ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/langsmith/home ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent'\n",
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company'\n",
      "page_content='##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/oss/python/deepagents/overview ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) ` ` LANGSMITH_TRACING=true `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹'\n",
      "page_content='--- Page: https://python.langchain.com/docs/introduction/ ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent\n",
      "\n",
      "` # pip install -qU langchain \"langchain[anthropic]\" from langchain.agents import create_agent def get_weather ( city : str ) -> str : \"\"\"Get weather for a given city.\"\"\" return f \"It's always sunny in { city } !\" agent = create_agent( model = \"claude-sonnet-4-5-20250929\" , tools = [get_weather], system_prompt = \"You are a helpful assistant\" , ) # Run the agent agent.invoke( { \"messages\" : [{ \"role\" : \"user\" , \"content\" : \"what is the weather in sf\" }]} ) `\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Core benefits\n",
      "\n",
      "## Standard model interface\n",
      "\n",
      "## Easy to use, highly flexible agent\n",
      "\n",
      "## Built on top of LangGraph\n",
      "\n",
      "## Debug with LangSmith\n",
      "\n",
      "Was this page helpful?\n",
      "\n",
      "Resources\n",
      "\n",
      "Company\n",
      "\n",
      "--- Page: https://python.langchain.com/ ---\n",
      "\n",
      "Python\n",
      "\n",
      "# LangChain overview\n",
      "\n",
      "LangChain is an open source framework with a pre-built agent architecture and integrations for any model or tool â€” so you can build agents that adapt as fast as the ecosystem evolves\n",
      "\n",
      "##\n",
      "\n",
      "â€‹\n",
      "\n",
      "Create an agent'\n",
      "Answer: Here's a concise comparison of LangChain, LangGraph, and LangSmith:\n",
      "\n",
      "**LangChain**: An open-source framework for building conversational AI agents that adapt to the evolving ecosystem. It provides a pre-built agent architecture, integrations for any model or tool, and a standard model interface.\n",
      "\n",
      "**LangGraph**: A component of LangChain that enables the creation of complex knowledge graphs, likely a graph-based data structure or library used to represent and manipulate knowledge graphs.\n",
      "\n",
      "**LangSmith**: A debugging tool for LangChain agents that allows developers to debug and visualize the behavior of their agents, identify issues, and optimize performance.\n",
      "\n",
      "In summary, LangChain is the overarching framework, LangGraph is a component that provides graph-related functionality, and LangSmith is a debugging tool that helps users develop and debug their agents.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"map_reduce\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c74f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Check out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\\n\\nIntroductions to all the key parts of LangChain youâ€™ll need to know! [ Here ](/docs/concepts/) you'll find high level explanations of all LangChain concepts.\\n\\nFor a deeper dive into LangGraph concepts, check out [ this page ](https://langchain-ai.github.io/langgraph/concepts/) .\\n\\n### [ Integrations ](/docs/integrations/providers/) \\u200b\\n\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with [ chat models ](/docs/integrations/chat/) , [ vector stores ](/docs/integrations/vectorstores/) , or other LangChain components from a specific provider, check out our growing list of [ integrations ](/docs/integrations/providers/) .\\n\\n### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\"\n",
      "page_content=\"` langchain-core ` ` langchain-openai ` ` langchain-anthropic ` ` langchain ` ` langchain-community ` ` langgraph `\\n\\n## Guides \\u200b\\n\\n### [ Tutorials ](/docs/tutorials/) \\u200b\\n\\nIf you're looking to build something specific or are more of a hands-on learner, check out our [ tutorials section ](/docs/tutorials/) . This is the best place to get started.\\n\\nThese are the best ones to get started with:\\n\\nExplore the full list of LangChain tutorials [ here ](/docs/tutorials/) , and check out other [ LangGraph tutorials here ](https://langchain-ai.github.io/langgraph/tutorials/) . To learn more about LangGraph, check out our first LangChain Academy course, _Introduction to LangGraph_ , available [ here ](https://academy.langchain.com/courses/intro-to-langgraph) .\\n\\n### [ How-to guides ](/docs/how_to/) \\u200b\\n\\n[ Here ](/docs/how_to/) youâ€™ll find short answers to â€œHow do Iâ€¦.?â€ types of questions. These how-to guides donâ€™t cover topics in depth â€“ youâ€™ll find that material in the [ Tutorials ](/docs/tutorials/) and the [ API Reference ](https://python.langchain.com/api_reference/) . However, these guides will help you quickly accomplish common tasks using [ chat models ](/docs/how_to/#chat-models) , [ vector stores ](/docs/how_to/#vector-stores) , and other common LangChain components.\\n\\nCheck out [ LangGraph-specific how-tos here ](https://langchain-ai.github.io/langgraph/how-tos/) .\\n\\n### [ Conceptual guide ](/docs/concepts/) \\u200b\"\n",
      "page_content=\"### [ API reference ](https://python.langchain.com/api_reference/) \\u200b\\n\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\n\\n## Ecosystem \\u200b\\n\\n### [ ðŸ¦œðŸ› ï¸ LangSmith ](https://docs.smith.langchain.com) \\u200b\\n\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you're developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/docs/troubleshooting/errors/ ---\\n\\n# Error reference\\n\\nThis page contains guides around resolving common errors you may find while building with LangChain. Errors referenced below will have an ` lc_error_code ` property corresponding to one of the below codes when they are thrown in code.\\n\\n` lc_error_code `\"\n",
      "page_content=\"## Core benefits Â¶\\n\\nLangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n\\n## LangGraphâ€™s ecosystem Â¶\\n\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nNote\\n\\nLooking for the JS version of LangGraph? See the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/) .\\n\\n## Additional resources Â¶\\n\\n## Acknowledgements Â¶\\n\\nLangGraph is inspired by [ Pregel ](https://research.google/pubs/pub37252/) and [ Apache Beam ](https://beam.apache.org/) . The public interface draws inspiration from [ NetworkX ](https://networkx.org/documentation/latest/) . LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\n\\n--- Page: https://python.langchain.com/docs/tutorials/ ---\\n\\n# Tutorials\\n\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\n\\n## Get started \\u200b\\n\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\"\n",
      "page_content='Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n\\n### [ ðŸ¦œðŸ•¸ï¸ LangGraph ](https://langchain-ai.github.io/langgraph) \\u200b\\n\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\\n\\n## Additional resources \\u200b\\n\\n### [ Versions ](/docs/versions/v0_3/) \\u200b\\n\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\n\\n### [ Security ](/docs/security/) \\u200b\\n\\nRead up on [ security ](/docs/security/) best practices to make sure you\\'re developing safely with LangChain.\\n\\n### [ Contributing ](/docs/contributing/) \\u200b\\n\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.\\n\\n--- Page: https://python.langchain.com/ ---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by large language models (LLMs).\\n\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the [ integrations ](/docs/integrations/providers/) page for more.\\n\\n` pip install -qU \"langchain[google-genai]\"\\n` ` import getpass\\nimport os'\n",
      "Answer: Based on the provided documents, here's a comparison of Langchain and LangGraph in bullet points:\n",
      "\n",
      "**Langchain vs LangGraph:**\n",
      "\n",
      "* **Purpose:**\n",
      "  * Langchain: A framework for developing applications powered by large language models (LLMs), simplifying every stage of the LLM application lifecycle.\n",
      "  * LangGraph: A specific part of the Langchain ecosystem, providing a deeper dive into LangGraph concepts, and can be used independently of LangChain. It's used for building stateful, multi-actor applications with LLMs.\n",
      "* **Documentation:**\n",
      "  * Langchain: Has a growing list of integrations, an API reference section for full documentation, a troubleshooting guide for resolving common errors, and tutorials, how-to guides, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own conceptual guide, a separate page for deeper dive into LangGraph concepts, a link to the LangChain Academy course on Introduction to LangGraph, and tutorials, how-to guides.\n",
      "* **Integration:**\n",
      "  * Langchain: Integrates with various tools and components, including chat models, vector stores, and other LangChain components.\n",
      "  * LangGraph: Integrates smoothly with LangChain, but can be used without it, and is used by production-grade agents trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* **Level of Explanation:**\n",
      "  * Langchain: Provides high-level explanations of all LangChain concepts.\n",
      "  * LangGraph: Offers a deeper dive into LangGraph concepts, suggesting a more detailed explanation.\n",
      "* **Learning Resources:**\n",
      "  * Langchain: Offers tutorials, how-to guides, an API reference, a troubleshooting guide, and a conceptual guide for learning.\n",
      "  * LangGraph: Has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Tutorials and Guides:**\n",
      "  * Langchain: Has a tutorials section with a list of tutorials, including a link to LangGraph tutorials, and a troubleshooting guide.\n",
      "  * LangGraph: Has its own tutorials section and how-to guides, with a link to the LangChain Academy course on Introduction to LangGraph.\n",
      "* **Core Benefits:**\n",
      "  * LangGraph: Provides low-level supporting infrastructure for any long-running, stateful workflow or agent, and does not abstract prompts or architecture.\n",
      "* **Ecosystem:**\n",
      "  * LangGraph: Integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents.\n",
      "* **Additional Resources:**\n",
      "  * LangGraph: The JS version of LangGraph is available on the [ JS repo ](https://github.com/langchain-ai/langgraphjs) and the [ JS docs ](https://langchain-ai.github.io/langgraphjs/).\n",
      "  * Langchain: Provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* **Inspiration:**\n",
      "  * LangGraph: Inspired by Pregel, Apache Beam, and NetworkX.\n",
      "\n",
      "**New Information:**\n",
      "\n",
      "* Langchain simplifies every stage of the LLM application lifecycle.\n",
      "* Langchain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers.\n",
      "* LangGraph is used for building stateful, multi-actor applications with LLMs.\n",
      "* LangGraph powers production-grade agents, trusted by LinkedIn, Uber, Klarna, GitLab, and many more.\n",
      "* Langchain provides a list of integrations, an API reference, and a troubleshooting guide.\n",
      "* LangGraph has its own tutorials, how-to guides, a conceptual guide, and a link to the LangChain Academy course on Introduction to LangGraph.\n"
     ]
    }
   ],
   "source": [
    "qa_groq_chain = load_groq_qa_chain(vectorstore, model_name=\"llama-3.1-8b-instant\", chain_type=\"refine\")\n",
    "result = qa_groq_chain({\"query\": query})\n",
    "\n",
    "for docs in result['source_documents']:\n",
    "    print(docs)\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
